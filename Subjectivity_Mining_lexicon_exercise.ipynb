{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Subjectivity Mining: lexicon-based approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "lexicon_wiegand_path = \"baseLexicon.txt\" \n",
    "lexicon_hurtlex_path = \"hurtlex_EN.tsv\" \n",
    "lexicon_mol_path = \"mol.csv\" \n",
    "test_set_path =  \"Subjectivity_mining_assignment_3_4_data/olid-test.csv\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load datasets in frames\n",
    "df_wiegand = pd.read_csv(lexicon_wiegand_path, delimiter='\\t', header=None) \n",
    "df_hurtlex = pd.read_csv(lexicon_hurtlex_path, delimiter='\\t')\n",
    "df_mol = pd.read_csv(lexicon_mol_path)\n",
    "df_test = pd.read_csv(test_set_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create merged lexicon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format Wiegand lexicon\n",
    "df_wiegand.columns = ['Word', 'Hateful'] \n",
    "df_wiegand['Word'] = df_wiegand['Word'].str.split('_').str.get(0)\n",
    "df_wiegand_hateful = df_wiegand[df_wiegand['Hateful'] == True]\n",
    "\n",
    "# Drop NaNs for MOL lexicon\n",
    "df_mol.dropna(subset=['en-american-english'], inplace=True)\n",
    "df_mol = df_mol[df_mol['en-american-english'] != '0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge lexicons and drop duplicates\n",
    "df_merged = pd.concat([df_wiegand_hateful['Word'], df_mol['en-american-english'], df_hurtlex['lemma']], ignore_index=True)\n",
    "df_merged.drop_duplicates(inplace=True)\n",
    "df_merged.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create lexicons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wiegand_lexicon = set(df_wiegand_hateful['Word'])\n",
    "hurtlex_lexicon = set(df_hurtlex['lemma'])\n",
    "mol_lexicon = set(df_mol['en-american-english'])\n",
    "merged_lexicon = set(df_merged)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run lexicon-based analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function checks whether word from lexicon is present in string\n",
    "def check_words(input_str, lexicon):\n",
    "    return any(word in input_str for word in lexicon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run analysis by checking if words in strings are present in lexicons\n",
    "df_analysis = df_test.copy()\n",
    "df_analysis.rename(columns={'labels': 'gold label'}, inplace=True)\n",
    "df_analysis['gold label'].replace({1: True, 0: False}, inplace=True)\n",
    "df_analysis['label wiegand'] = df_analysis['text'].apply(lambda x: check_words(x, wiegand_lexicon))\n",
    "df_analysis['label hurtlex'] = df_analysis['text'].apply(lambda x: check_words(x, hurtlex_lexicon))\n",
    "df_analysis['label mol'] = df_analysis['text'].apply(lambda x: check_words(x, mol_lexicon))\n",
    "df_analysis['label merged'] = df_analysis['text'].apply(lambda x: check_words(x, merged_lexicon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>gold label</th>\n",
       "      <th>label wiegand</th>\n",
       "      <th>label hurtlex</th>\n",
       "      <th>label mol</th>\n",
       "      <th>label merged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15923</td>\n",
       "      <td>#WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>27014</td>\n",
       "      <td>#ConstitutionDay is revered by Conservatives, ...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30530</td>\n",
       "      <td>#FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13876</td>\n",
       "      <td>#Watching #Boomer getting the news that she is...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60133</td>\n",
       "      <td>#NoPasaran: Unity demo to oppose the far-right...</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>855</th>\n",
       "      <td>73439</td>\n",
       "      <td>#DespicableDems lie again about rifles. Dem Di...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>856</th>\n",
       "      <td>25657</td>\n",
       "      <td>#MeetTheSpeakers ðŸ™Œ @USER will present in our e...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>857</th>\n",
       "      <td>67018</td>\n",
       "      <td>3 people just unfollowed me for talking about ...</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>858</th>\n",
       "      <td>50665</td>\n",
       "      <td>#WednesdayWisdom Antifa calls the right fascis...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>859</th>\n",
       "      <td>24583</td>\n",
       "      <td>#Kavanaugh typical #liberals , #Democrats URL</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>860 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  gold label  \\\n",
       "0    15923  #WhoIsQ #WheresTheServer #DumpNike #DECLASFISA...        True   \n",
       "1    27014  #ConstitutionDay is revered by Conservatives, ...       False   \n",
       "2    30530  #FOXNews #NRA #MAGA #POTUS #TRUMP #2ndAmendmen...       False   \n",
       "3    13876  #Watching #Boomer getting the news that she is...       False   \n",
       "4    60133  #NoPasaran: Unity demo to oppose the far-right...        True   \n",
       "..     ...                                                ...         ...   \n",
       "855  73439  #DespicableDems lie again about rifles. Dem Di...        True   \n",
       "856  25657  #MeetTheSpeakers ðŸ™Œ @USER will present in our e...       False   \n",
       "857  67018  3 people just unfollowed me for talking about ...        True   \n",
       "858  50665  #WednesdayWisdom Antifa calls the right fascis...       False   \n",
       "859  24583      #Kavanaugh typical #liberals , #Democrats URL       False   \n",
       "\n",
       "     label wiegand  label hurtlex  label mol  label merged  \n",
       "0             True           True       True          True  \n",
       "1             True           True       True          True  \n",
       "2            False           True       True          True  \n",
       "3            False          False      False         False  \n",
       "4            False           True       True          True  \n",
       "..             ...            ...        ...           ...  \n",
       "855           True           True       True          True  \n",
       "856          False           True       True          True  \n",
       "857           True           True       True          True  \n",
       "858          False           True       True          True  \n",
       "859          False           True       True          True  \n",
       "\n",
       "[860 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_analysis.to_csv(\"results/df_analysis.csv\")\n",
    "df_analysis"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "545e036c4b32438aced1f6b3c8d38ca151d9c36189e05839cb0aa568fda70ddd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
